# Î¤Î¿Ï€Î¿Î¸Î­Ï„Î·ÏƒÎµ Î±Ï…Ï„Î­Ï‚ Ï„Î¹Ï‚ Î³ÏÎ±Î¼Î¼Î­Ï‚ Î‘ÎœÎ•Î£Î‘ ÏƒÏ„Î·Î½ ÎºÎ¿ÏÏ…Ï†Î® Ï„Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï…
import pysqlite3
import sys
sys.modules["sqlite3"] = sys.modules["pysqlite3"]

# Î‘Ï€Î±ÏÎ±Î¯Ï„Î·Ï„ÎµÏ‚ ÎµÎ¹ÏƒÎ±Î³Ï‰Î³Î­Ï‚
import streamlit as st
import os
import asyncio
import mysql.connector
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain.chains import ConversationalRetrievalChain
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.documents import Document

# Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Ï„Î¿Ï… asyncio event loop
try:
    _ = asyncio.get_running_loop()
except RuntimeError as ex:
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)

# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï„Î¿Ï… Gemini Pro Î¼Î¿Î½Ï„Î­Î»Î¿Ï…
llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0.5, google_api_key=st.secrets["keys"]["GOOGLE_API_KEY"])

# --- Î‘ÏƒÏ†Î±Î»Î®Ï‚ Î£ÏÎ½Î´ÎµÏƒÎ· ÏƒÏ„Î· Î’Î¬ÏƒÎ· Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ MySQL ---
@st.cache_resource
def get_database_connection():
    """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î¼Î¹Î± ÏƒÏÎ½Î´ÎµÏƒÎ· ÏƒÏ„Î· Î²Î¬ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ MySQL."""
    try:
        conn = mysql.connector.connect(
            host=st.secrets["database"]["host"],
            user=st.secrets["database"]["user"],
            password=st.secrets["database"]["password"],
            database=st.secrets["database"]["db"]
        )
        return conn
    except Exception as e:
        st.error(f"Î£Ï†Î¬Î»Î¼Î± ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚ ÏƒÏ„Î· Î²Î¬ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½: {e}")
        return None

# --- Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÎºÎ±Î¹ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± RAG ---
@st.cache_resource
def process_data_from_db(data_from_db):
    """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Ï„Î¿ RAG ÏƒÏÏƒÏ„Î·Î¼Î± Î±Ï€ÏŒ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Ï€Î¿Ï… Ï€ÏÎ¿Î­ÏÏ‡Î¿Î½Ï„Î±Î¹ Î±Ï€ÏŒ Ï„Î· Î²Î¬ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½."""
    st.info("Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½...")
    
    documents = []
    if not data_from_db:
        st.warning("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±.")
        return None

    for idx, row in enumerate(data_from_db):
        content = " ".join(str(item) for item in row)
        documents.append(Document(page_content=content, metadata={"source": f"Database Row {idx+1}"}))
        
    st.write(f"Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(documents)} Î³ÏÎ±Î¼Î¼Î­Ï‚ Î³Î¹Î± ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±.")

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len
    )
    text_chunks = text_splitter.split_documents(documents)
    
    embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")
    vector_store = Chroma.from_documents(text_chunks, embeddings)
    
    qa_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vector_store.as_retriever(),
        return_source_documents=True
    )
    return qa_chain

# --- ÎšÎµÎ½Ï„ÏÎ¹ÎºÎ® Î›Î¿Î³Î¹ÎºÎ® Ï„Î·Ï‚ Î•Ï†Î±ÏÎ¼Î¿Î³Î®Ï‚ ---
st.set_page_config(page_title="MySQL & Gemini Chatbot", layout="wide")
st.header("ğŸ’¬ Chatbot Î¼Îµ Î”ÎµÎ´Î¿Î¼Î­Î½Î± Î±Ï€ÏŒ MySQL")

# Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î¹ÏƒÏ„Î¿ÏÎ¹ÎºÎ¿Ï ÏƒÏ…Î½Î¿Î¼Î¹Î»Î¯Î±Ï‚ ÎºÎ±Î¹ QA chain
if "messages" not in st.session_state:
    st.session_state.messages = []
if "qa_chain" not in st.session_state:
    st.session_state.qa_chain = None

# Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Ï†ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎµÎºÎºÎ¯Î½Î·ÏƒÎ·
if st.session_state.qa_chain is None:
    st.info("Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±Ï€ÏŒ Ï„Î¿Î½ Ï€Î¯Î½Î±ÎºÎ± 'table1'...")
    conn = get_database_connection()
    if conn:
        try:
            with conn.cursor() as cursor:
                cursor.execute("SELECT * FROM table1;")
                results = cursor.fetchall()
            if results:
                st.session_state.qa_chain = process_data_from_db(results)
                st.success("Î¤Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Ï†Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ Î¼Îµ ÎµÏ€Î¹Ï„Ï…Ï‡Î¯Î±! ÎœÏ€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± Î¾ÎµÎºÎ¹Î½Î®ÏƒÎµÏ„Îµ Ï„Î· ÏƒÏ…Î½Î¿Î¼Î¹Î»Î¯Î±.")
            else:
                st.warning("ÎŸ Ï€Î¯Î½Î±ÎºÎ±Ï‚ 'table1' ÎµÎ¯Î½Î±Î¹ Î¬Î´ÎµÎ¹Î¿Ï‚ Î® Ï„Î¿ query Î´ÎµÎ½ ÎµÏ€Î­ÏƒÏ„ÏÎµÏˆÎµ Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±.")
                st.session_state.qa_chain = None
        except Exception as e:
            st.error(f"Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎµÎºÏ„Î­Î»ÎµÏƒÎ· Ï„Î¿Ï… query: {e}")
            st.session_state.qa_chain = None
    else:
        st.error("Î”ÎµÎ½ Î®Ï„Î±Î½ Î´Ï…Î½Î±Ï„Î® Î· ÏƒÏÎ½Î´ÎµÏƒÎ· ÏƒÏ„Î· Î²Î¬ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½.")

# Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Ï„Î¿Ï… chatbot Î¼ÏŒÎ½Î¿ Î±Î½ Î­Ï‡ÎµÎ¹ Ï†Î¿ÏÏ„Ï‰Î¸ÎµÎ¯ Ï„Î¿ QA chain
if st.session_state.qa_chain:
    st.write("---")
    
    # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Ï„Î¿Ï… Î¹ÏƒÏ„Î¿ÏÎ¹ÎºÎ¿Ï ÏƒÏ…Î½Î¿Î¼Î¹Î»Î¯Î±Ï‚
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Î•Î¯ÏƒÎ¿Î´Î¿Ï‚ Ï‡ÏÎ®ÏƒÏ„Î·
    if prompt := st.chat_input("Î¡ÏÏ„Î·ÏƒÎ­ Î¼Îµ ÎºÎ¬Ï„Î¹ Î³Î¹Î± Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Î Î±ÏÎ±Î³Ï‰Î³Î® Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·Ï‚ Î±Ï€ÏŒ Ï„Î¿ chatbot
        with st.chat_message("assistant"):
            last_two_messages = st.session_state.messages[-2:]
            chat_history_formatted = [
                HumanMessage(content=msg["content"]) if msg["role"] == "user" else AIMessage(content=msg["content"])
                for msg in last_two_messages
            ]

            response = st.session_state.qa_chain({"question": prompt, "chat_history": chat_history_formatted})
            answer = response["answer"]
            st.markdown(answer)

        st.session_state.messages.append({"role": "assistant", "content": answer})
